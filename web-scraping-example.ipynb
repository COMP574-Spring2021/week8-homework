{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scrapping with BeautifulSoup Example \n",
    "Adapted from [here](https://www.digitalocean.com/community/tutorials/how-to-scrape-web-pages-with-beautiful-soup-and-python-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://web.archive.org/web/20121007172955/https://www.nga.gov/collection/anZ1.htm')\n",
    "type(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "# soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull all text from the BodyText div\n",
    "artist_name_list = soup.find(class_='BodyText')\n",
    "type(artist_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull text from all instances of <a> tag within BodyText div\n",
    "artist_name_list_items = artist_name_list.find_all('a')\n",
    "type(artist_name_list_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create for loop to print out all artists' names\n",
    "for artist_name in artist_name_list_items:\n",
    "    print(artist_name.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-artist <a> elements at the bottom of the page. \n",
    "last_links = soup.find(class_='AlphaNav')\n",
    "last_links.decompose()\n",
    "\n",
    "artist_name_list = soup.find(class_='BodyText')\n",
    "artist_name_list_items = artist_name_list.find_all('a')\n",
    "\n",
    "for artist_name in artist_name_list_items:\n",
    "    print(artist_name.contents[0])\n",
    "    #print(artist_name.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .contents to pull out the <a> tagâ€™s children\n",
    "for artist_name in artist_name_list_items:\n",
    "    names = artist_name.contents[0]\n",
    "    links = 'https://web.archive.org' + artist_name.get('href')\n",
    "    print(names)\n",
    "    print(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we write the data into a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "f = open('z-artist-names.csv', 'w', newline='')\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(['Name', 'Link']) # write the header row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist_name in artist_name_list_items:\n",
    "    names = artist_name.contents[0]\n",
    "    links = 'https://web.archive.org' + artist_name.get('href')\n",
    "    print(names)\n",
    "    print(links)\n",
    "    writer.writerow([names, links])\n",
    "f.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_entry_items = artist_name_list.find_all('tr')\n",
    "artist_entry_items\n",
    "\n",
    "# for artist_info in artist_entry_items:\n",
    "    # print(str(artist_info.td.next_sibling.contents[0]) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist_info in artist_entry_items:\n",
    "    print(artist_info.prettify())\n",
    "    nationality = artist_info.findChildren()[2].contents\n",
    "    name = artist_info.findChildren()[1].contents[0]\n",
    "    print('----')\n",
    "    print(name)\n",
    "    print('----')\n",
    "    link = artist_info.findChildren()[0].contents[0]\n",
    "    link = str(link).split('\\\"')[1]\n",
    "    link = \"https://web.archive.org\" + link\n",
    "    print('----')\n",
    "    print(link)\n",
    "    print('----')\n",
    "    if nationality :\n",
    "        nationality_str  = str(nationality[0]).split(',')[0]\n",
    "        print('----')\n",
    "        print(nationality_str)\n",
    "        print('----')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}